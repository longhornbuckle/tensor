<pre class='metadata'>
Title: The Tensor
Shortname: the-tensor
Status: iso/WD
Group: iso
Level: 0
URL: https://github.com/longhornbuckle/tensor
Editor: Richard Warren Hornbuckle, longhornbuckle@utexas.edu
Editor: Enrico Mauro, aurumpuro@gmail.com
Editor Term: Author, Authors
Abstract: A proposal for a C++ STL tensor container.
Boilerplate: omit conformance
Boilerplate: omit copyright
Boilerplate: style-syntax-highlighting off
</pre>

Introduction {#intro}
=====================

Tensor is a container that reinterprets a contiguous buffer as a multidimensional array.
It provides an interface to perform Linear Algebra operations.
It is an evolution of the std::valarray and std::vector templates into a multidimensional context - incorporating many concepts introduced via std::mdspan.
Furthermore, it introduces an interface that allows the user to perform operations on a multidimensional container and guarantees a large margin of customization.

Motivation and Scope {#motiv}
=============================

The motivation of this proposal is to provide a foundational container from which the standard can expand linear algebraic operations.

More specifically, this proposal seeks to establish:
- A multidimensional container which:
    - Provides valarray-like interfaces and efficiency.
    - Provides vector-like functionality in multiple dimensions.
    - Makes use of layout and accessor policy concepts established via mdspan.
- A unifying relationship between vectors (rank 1 tensors), matrices (rank 2 tensors), and more generic N-dimensional tensors.
- A framework for defining efficient implementations of linear algebraic functions using concepts and template expression types.

This proposal differs from a couple similar existing works:
- D1684R0 mdarray: The authors do not believe this work is incompatable with this proposal.
However, the authors of this work take a different approach of essentially defining an adaptor which reinterpret's an owned container with single dimensional access into a multidimensional framework.
While such an adaptor may be useful, it both significant obscurs behavior and constrains the implementation to the frameworks of existing containers.
- P1385 also seeks to establish linear algebra support in the standard and would be in conflict with this proposal.
The authors have the following concerns in regards to the current iteration of P1385:
    - The proposal too narrowly focuses on rank 2 tensors (matrices). The authors believe an expandable framework establishing the relationship between a vector, matrix, and generic tensor is needed. Failing to address this risks making further proposals more complex and difficult.
    - The proposal does not address unifying the relationship between its proposal engine types and mdspan. While these two are not incongruent, failure to consider how the two interact could overcomplicate the standard. Rather than attemping to enforce layout and accessor policies into a new engine paradigm, the authors (of this proposal) adopt the mdspan paradigms wholesale.
    - The proposal introduces additional template parameters for overloading function behavior. The authors find this overcomplicated, potentially confusing, difficult to specialize, and unnecessary. If specialized behavior is desired, additional namespaces and traditional functional overloading could be used to achieve the same affect.

The scope of this proposal is contained to the definition of this new container as well as related class and concepts.

Description {#descript}
=======================

<h3>Concepts</h3>

<h4>Tensor Expression</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept tensor_expression = requires
{
  typename T::value_type;
  typename T::index_type;
  typename T::size_type;
  typename T::extents_type;
  typename T::rank_type;
} &&
requires( const T& t, typename T::rank_type n )
{
  { t.extent( n ) } noexcept -> same_as< typename T::size_type >;
  { T::rank() }     noexcept -> same_as< typename T::rank_type >;
  { t.extents() }   noexcept -> convertible_to< typename T::extents_type >;
  integral_constant< typename T::rank_type, T::rank() >::value;
} &&
requires( T& t, auto ... indices )
{
  { t.operator[]( indices ... ) } -> convertible_to< typename T::value_type >;
}
</code>
</pre>

<h4>Tensor View</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept tensor_view =
tensor_expression< T > &&
requires
{
  typename T::layout_type;
  typename T::accessor_type;
  typename T::reference;
  typename T::data_handle_type;
  typename T::mapping_type;
} &&
requires( const T& t, typename T::rank_type n )
{
  { T::rank_dynamic() }         noexcept -> same_as< typename T::rank_type >;
  { T::static_extent( n ) }     noexcept -> same_as< typename T::size_type >;
  { T::is_always_strided() }    noexcept -> same_as< bool >;
  { T::is_always_exhaustive() } noexcept -> same_as< bool >;
  { T::is_always_unique() }     noexcept -> same_as< bool >;
  { t.is_strided() }            noexcept -> same_as< bool >;
  { t.is_exhaustive() }         noexcept -> same_as< bool >;
  { t.is_unique() }             noexcept -> same_as< bool >;
  { t.stride( n ) }             noexcept -> same_as< typename T::index_type >;
  { t.accessor() }              noexcept -> convertible_to< typename T::accessor_type >;
  { t.data_handle() }           noexcept -> convertible_to< typename T::data_handle_type >;
  { t.mapping() }               noexcept -> convertible_to< typename T::mapping_type >;
  integral_constant< typename T::rank_type, T::rank_dynamic() >::value;
  integral_constant< typename T::size_type, T::static_extent( n ) >::value;
  bool_constant< T::is_always_strided() >::value;
  bool_constant< T::is_always_exhaustive() >::value;
  bool_constant< T::is_always_unique() >::value;
} &&
requires( T& t, auto ... indices )
{
  { t.operator[]( indices ... ) } -> same_as< typename T::reference >;
} &&
</code>
</pre>

<h4>Owning Tensor</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept owning_tensor< T > =
tensor_view< T > &&
requires( const T& t )
{
  { t.size() } noexcept -> same_as< typename T::size_type >;
};
</code>
</pre>

<h4>Writable Tensor</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept writable_tensor =
owning_tensor< T > &&
requires( T& t, typename T::value_type v, auto ... indices )
{
  { t.operator[]( indices ... ) = v } -> same_as<typename T::reference>;
};
</code>
</pre>

<h4>Static Tensor</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept static_tensor =
owning_tensor< T > &&
( T::rank_dynamic() == 0 ) &&
requires
{
  { T {} };
};
</code>
</pre>

<h4>Dynamic Tensor</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept dynamic_tensor =
tensor_view< T > &&
requires
{
  typename T::allocator_type
} &&
requires( const T& t, typename T::extents_type s, typename T::allocator_type alloc )
{
  { t.max_size() -> same_as< typename T::size_type > };
  { t.capacity() -> same_as< typename T::size_type > };
  { t.resize( s ) };
  // TBD on capacity_extents()
  // TBD on reserve( ... )
  { t.get_allocator() } -> same_as< typename T::allocator_type >;
  { T( alloc ) };
  { T( s, alloc ) };
};
</code>
</pre>

<h3>Tensor</h3>
<pre class="highlight">
<code class="language-c++">
template < class T,
           class Extents,
           class LayoutPolicy   = layout_right,
           class Allocator      = allocator<T>,
           class AccessorPolicy = default_accessor<T> >
class tensor
{
  public:
    using value_type       = T;
    using accessor_type    = AccessorPolicy;
    using reference        = typename accessor_type::reference;
    using const_reference  = add_const_t<typename accessor_type::reference>;
    using data_handle_type = typename accessor_type::data_handle_type;
    using extents_type     = Extents;
    using index_type       = typename extents_type::index_type;
    using size_type        = typename extents_type::size_type;
    using rank_type        = typename extents_type::rank_type;
    using layout_type      = LayoutPolicy;
    using mapping_type     = typename layout_type::template mapping<Extents>;
    using allocator_type   = Allocator;
    
    // Constructors
    constexpr tensor();
    explicit constexpr tensor( const allocator_type& alloc );
    explicit constexpr tensor( const extents_type& s, const allocator_type& alloc = allocator_type() );
    explicit constexpr tensor( const mapping_type& m, const allocator_type& alloc = allocator_type() );

    constexpr tensor( const initializer_list< value_type >& il, const extents_type& s, const allocator_type& alloc = allocator_type() );
    constexpr tensor( const initializer_list< value_type >& il, const mapping_type& m, const allocator_type& alloc = allocator_type() );
    
    template < class InputIt >
    constexpr tensor( InputIt first, InputIt last, const extents_type& s, const allocator_type& alloc = allocator_type() );
    template < class InputIt >
    constexpr tensor( InputIt first, InputIt last, const mapping_type& m, const allocator_type& alloc = allocator_type() );
    
    template < class R >
    constexpr tensor( [[maybe_unused]] from_range_t, R&& rg, const extents_type& s, const allocator_type& alloc = allocator_type() );
    template < class R >
    constexpr tensor( [[maybe_unused]] from_range_t, R&& rg, const mapping_type& m, const allocator_type& alloc = allocator_type() );

    // NOTE: These constructors require one of:
    //    A: ( extents_type::rank_dynamic() == 0 ) && ( mapping_type().required_span_size() == size of initializer_list, iterator pair, or range )
    //    B: ( extents_type::rank_dynamic() == 1 ) && ( mapping_type( extents_type(N) ).required_span_size() == size of initializer_list, iterator pair, or range ) (for some integer value N)
    explicit constexpr tensor( const initializer_list< value_type >& il, const allocator_type& alloc = allocator_type() );
    template < class InputIt >
    constexpr tensor( InputIt first, InputIt last, const allocator_type& alloc = allocator_type() );
    template < class R >
    constexpr tensor( [[maybe_unused]] from_range_t, R&& rg, const allocator_type& alloc = allocator_type() );
    
    template < tensor_expression Tensor >
    explicit constexpr tensor( const Tensor& t, const allocator_type& alloc = allocator_type() );

    constexpr tensor( const tensor& rhs );
    constexpr tensor( const tensor& rhs, const allocator_type& alloc );
    constexpr tensor( tensor&& rhs );
    constexpr tensor( tensor&& rhs, const allocator_type& alloc );

    // Destructor
    constexpr ~tensor();

    // Assignment
    constexpr tensor& operator = ( tensor&& rhs ) noexcept( allocator_traits< allocator_type >::propagate_on_container_move_assignment &&
                                                            allocator_traits< allocator_type >::is_always_equal );
    constexpr tensor& operator = ( const tensor& rhs );
    template < tensor_expression Tensor >
    constexpr tensor& operator = ( const Tensor& rhs );
    // NOTE: This assignment operator requires the same requirements as the constructors
    constexpr tensor& operator = ( const initializer_list< value_type > il );

    // Members
    constexpr swap( tensor& rhs ) noexcept( allocator_traits< allocator_type >::propagate_on_container_swap &&
                                            allocator_traits< allocator_type >::is_always_equal )
    [[nodiscard]] constexpr bool empty() const noexcept;
    [[nodiscard]] constexpr const extents_type& extents() const noexcept;
    [[nodiscard]] constexpr size_type extent( rank_type n ) const noexcept;
    [[nodiscard]] static constexpr size_type static_extent( rank_type n ) noexcept;
    [[nodiscard]] constexpr size_type size() const noexcept;
    [[nodiscard]] constexpr size_type max_size() const noexcept;
    [[nodiscard]] constexpr size_type capacity() const noexcept;
    constexpr void resize( const extents_type& new_size );
    constexpr void resize( const extents_type& new_size, const value_type& value );
    constexpr void reserve( const extents_type& new_cap );
    constexpr void shrink_to_fit();
    [[nodiscard]] constexpr bool is_unique() const noexcept;
    [[nodiscard]] constexpr bool is_exhaustive() const noexcept;
    [[nodiscard]] constexpr bool is_strided() const noexcept;
    [[nodiscard]] static constexpr bool is_always_unique() noexcept;
    [[nodiscard]] static constexpr bool is_always_exhaustive() noexcept;
    [[nodiscard]] static constexpr bool is_always_strided() noexcept;
    [[nodiscard]] static constexpr rank_type rank() noexcept;
    [[nodiscard]] static constexpr rank_type rank_dynamic() noexcept;
    [[nodiscard]] constexpr size_type stride( rank_type n ) const noexcept;
    [[nodiscard]] constexpr const mapping_type& mapping() const noexcept;
    [[nodiscard]] constexpr const data_handle_type& data_handle() const noexcept;
    [[nodiscard]] constexpr data_handle_type& data_handle() noexcept;
    [[nodiscard]] constexpr allocator_type get_allocator() const noexcept;
    [[nodiscard]] constexpr const accessor_type& accessor() const noexcept;

    template < class ... OtherIndexType >
    [[nodiscard]] constexpr const_reference operator[]( OtherIndexType ... indices ) const;
    template < class ... OtherIndexType >
    [[nodiscard]] constexpr reference operator[]( OtherIndexType ... indices );

    template < tensor_expression Tensor >
    constexpr tensor& operator+=( const Tensor& t );
    template < tensor_expression Tensor >
    constexpr tensor& operator-=( const Tensor& t );
    constexpr tensor& operator*=( const value_type& value );
    constexpr tensor& operator/=( const value_type& value );
    constexpr tensor& operator%=( const value_type& value );
    constexpr tensor& operator&=( const value_type& value );
    constexpr tensor& operator|=( const value_type& value );
    constexpr tensor& operator^=( const value_type& value );
    constexpr tensor& operator>>=( const value_type& value );
    constexpr tensor& operator<<=( const value_type& value );
};

// Non-member functions
// Addition
// Substraction
// Negation
// Scalar Multiplication
// Scalar Division
// Matrix Multiplication
// Vector-Matrix Multiplication
// Vector Inner Product
// Vector Outer Product
// Transpose
// Conjugate
// Modulo

</code>
</pre>

Mandates:
- T is a complete object type that is neither an abstract class type nor an array type.
- is_same_v< Allocator::value_type, T > is true.
- is_same_v< AccessorPolicy::element_type, T > is true.
- Extents is a specialization of extents.
- Allocator shall meet the allocator requirements.
- LayoutPolicy shall meet the layout mapping policy requirements.
- AccessorPolicy shall meet the accessor policy requirements.

<h3>Tensor Expressions</h3>
TODO: Tensor Expressions

Design Questions {#questions}
=============================

<h3>Fixed Size Tensor</h3>
A) fs_tensor and dr_tensor
B) tensor fixed size buffer and allocator specialization
C) Don't address

<h3>Capacity and Reserve</h3>
A) reserve( size_type )
B) reserve( extents_type )
C) Additional capacity Extents template parameter

<h3>Dynamic Only Extents</h3>
Avoids allocation on construction

<h3>[[[nodiscard]]] clarification</h3>
P0009 and P0600

<h3>Safe Memory Access</h3>
at(...)

<h3>Resize mapping_type</h3>
How should resize work?

<h3>Noexcept Swap and Move Mapping and AccessorPolicy</h3>
If the allocator is swappable and moveable, then container swap and move is expected to be noexcept. This requires additional constraints on mapping and accessor.

<h3>[[ assume( restrict p ) ]]</h3>
Owning tensor concepts may use such in a way similar to C99 restrict to achieve valarray-like optimization

<h3>Vector and Matrix Aliases</h3>

<h3>Limitations without Iterators</h3>
Some constructors/functions don't work well

<h3>Element-wise Functions</h3>
element-wise multiply and divide

<h3>Comparison Operators</h3>
Defining a norm

<h3>mdslice or subtensor</h3>
How should non-owning views be created. Relevant: P2630

<h3>Additional Vector-like functions</h3>
push_front, emplace_front, push_back, emplace_back, insert, ...

<h3>Rank One Extents Implicit Conversions</h3>
alleviates verbosity of rank one tensors

Acknowledgements {#acknowledge}
===============================

Related Work {#related}
=======================