<pre class='metadata'>
Title: The Tensor
Shortname: the-tensor
Status: iso/WD
Group: iso
Level: 0
URL: https://github.com/longhornbuckle/tensor
Editor: Richard Warren Hornbuckle, longhornbuckle@utexas.edu
Editor: Enrico Mauro, aurumpuro@gmail.com
Editor Term: Author, Authors
Abstract: A proposal for a C++ STL tensor container.
Boilerplate: omit conformance
Boilerplate: omit copyright
Boilerplate: style-syntax-highlighting off
</pre>

Introduction {#intro}
=====================

Tensor is a container that reinterprets a contiguous buffer as a multidimensional array.
It provides an interface to perform Linear Algebra operations.
It is an evolution of the std::valarray and std::vector templates into a multidimensional context - incorporating many concepts introduced via std::mdspan.
Furthermore, it introduces an interface that allows the user to perform operations on a multidimensional container and guarantees a large margin of customization.

Motivation and Scope {#motiv}
=============================

The motivation of this proposal is to provide a foundational container from which the standard can expand linear algebraic operations.

More specifically, this proposal seeks to establish:
- A multidimensional container which:
    - Provides valarray-like interfaces and efficiency.
    - Provides vector-like functionality in multiple dimensions.
    - Makes use of layout and accessor policy concepts established via mdspan.
- A unifying relationship between vectors (rank 1 tensors), matrices (rank 2 tensors), and more generic N-dimensional tensors.
- A framework for defining efficient implementations of linear algebraic functions using concepts and template expression types.

This proposal differs from a couple similar existing works:
- D1684 mdarray: The authors do not believe this work is incompatable with this proposal.
However, the authors of this work take a different approach of essentially defining an adaptor which reinterpret's an owned container with single dimensional access into a multidimensional framework.
While such an adaptor may be useful, it both significant obscurs behavior and constrains the implementation to the frameworks of existing containers.
- P1385 also seeks to establish linear algebra support in the standard and would be in conflict with this proposal.
The authors have the following concerns in regards to the current iteration of P1385:
    - The proposal too narrowly focuses on rank 2 tensors (matrices). The authors believe an expandable framework establishing the relationship between a vector, matrix, and generic tensor is needed. Failing to address this risks making further proposals more complex and difficult.
    - The proposal does not address unifying the relationship between its proposal engine types and mdspan. While these two are not incongruent, failure to consider how the two interact could overcomplicate the standard. Rather than attemping to enforce layout and accessor policies into a new engine paradigm, the authors (of this proposal) adopt the mdspan paradigms wholesale.
    - The proposal introduces additional template parameters for overloading function behavior. The authors find this overcomplicated, potentially confusing, difficult to specialize, and unnecessary. If specialized behavior is desired, additional namespaces and traditional functional overloading could be used to achieve the same affect.

The scope of this proposal is contained to the definition of this new container as well as related class and concepts.

Description {#descript}
=======================

<h3>Concepts</h3>

<h4>Tensor Expression</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept tensor_expression = requires
{
  typename T::value_type;
  typename T::index_type;
  typename T::size_type;
  typename T::extents_type;
  typename T::rank_type;
} &&
requires( const T& t, typename T::rank_type n )
{
  { t.extent( n ) } noexcept -> same_as< typename T::size_type >;
  { T::rank() }     noexcept -> same_as< typename T::rank_type >;
  { t.extents() }   noexcept -> convertible_to< typename T::extents_type >;
  integral_constant< typename T::rank_type, T::rank() >::value;
} &&
requires( T& t, auto ... indices )
{
  { t.operator[]( indices ... ) } -> convertible_to< typename T::value_type >;
}
</code>
</pre>

<h4>Tensor View</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept tensor_view =
tensor_expression< T > &&
requires
{
  typename T::layout_type;
  typename T::accessor_type;
  typename T::reference;
  typename T::data_handle_type;
  typename T::mapping_type;
} &&
requires( const T& t, typename T::rank_type n )
{
  { T::rank_dynamic() }         noexcept -> same_as< typename T::rank_type >;
  { T::static_extent( n ) }     noexcept -> same_as< typename T::size_type >;
  { t.size() }                  noexcept -> same_as< typename T::size_type >;
  { T::is_always_strided() }    noexcept -> same_as< bool >;
  { T::is_always_exhaustive() } noexcept -> same_as< bool >;
  { T::is_always_unique() }     noexcept -> same_as< bool >;
  { t.is_strided() }            noexcept -> same_as< bool >;
  { t.is_exhaustive() }         noexcept -> same_as< bool >;
  { t.is_unique() }             noexcept -> same_as< bool >;
  { t.stride( n ) }             noexcept -> same_as< typename T::index_type >;
  { t.accessor() }              noexcept -> convertible_to< typename T::accessor_type >;
  { t.data_handle() }           noexcept -> convertible_to< typename T::data_handle_type >;
  { t.mapping() }               noexcept -> convertible_to< typename T::mapping_type >;
  integral_constant< typename T::rank_type, T::rank_dynamic() >::value;
  integral_constant< typename T::size_type, T::static_extent( n ) >::value;
  bool_constant< T::is_always_strided() >::value;
  bool_constant< T::is_always_exhaustive() >::value;
  bool_constant< T::is_always_unique() >::value;
} &&
requires( T& t, auto ... indices )
{
  { t.operator[]( indices ... ) } -> same_as< typename T::reference >;
} &&
</code>
</pre>

<h4>Writable Tensor</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept writable_tensor =
tensor_view< T > &&
requires( T& t, typename T::value_type v, auto ... indices )
{
  { t.operator[]( indices ... ) = v } -> same_as<typename T::reference>;
};
</code>
</pre>

<h4>Static Tensor</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept static_tensor =
tensor_view< T > &&
( T::rank_dynamic() == 0 ) &&
requires
{
  { T {} };
};
</code>
</pre>

<h4>Dynamic Tensor</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept dynamic_tensor =
tensor_view< T > &&
requires
{
  typename T::allocator_type
} &&
requires( const T& t, typename T::extents_type s, typename T::allocator_type alloc )
{
  { t.max_size() -> same_as< typename T::size_type > };
  { t.capacity() -> same_as< typename T::size_type > };
  { t.resize( s ) };
  // TBD on capacity_extents()
  // TBD on reserve( ... )
  { t.get_allocator() } -> same_as< typename T::allocator_type >;
  { T( alloc ) };
  { T( s, alloc ) };
};
</code>
</pre>

<h4>Unary Tensor Expression</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept unary_tensor_expression =
tensor_expression< T > &&
requires ( T t )
{
  { t.underlying() } -> tensor_expression;
  { t.operator auto() };
} &&
( static_tensor< decltype( declval< T >().operator auto() ) > ||
  dynamic_tensor< decltype( declval< T >().operator auto() ) > );
</code>
</pre>

<h4>Binary Tensor Expression</h4>
<pre class="highlight">
<code class="language-c++">
template < class T >
concept binary_tensor_expression =
tensor_expression< T > &&
requires ( T t )
{
  { t.first() } -> tensor_expression;
  { t.second() } -> tensor_expression;
  { t.operator auto() };
} &&
( static_tensor< decltype( declval< T >().operator auto() ) > ||
  dynamic_tensor< decltype( declval< T >().operator auto() ) > );
</code>
</pre>

<h3>Tensor</h3>
<pre class="highlight">
<code class="language-c++">
template < class T,
           class Extents,
           class LayoutPolicy   = layout_right,
           class Allocator      = allocator<T>,
           class AccessorPolicy = default_accessor<T> >
class tensor
{
  public:
    using value_type       = T;
    using accessor_type    = AccessorPolicy;
    using reference        = typename accessor_type::reference;
    using const_reference  = add_const_t<typename accessor_type::reference>;
    using data_handle_type = typename accessor_type::data_handle_type;
    using extents_type     = Extents;
    using index_type       = typename extents_type::index_type;
    using size_type        = typename extents_type::size_type;
    using rank_type        = typename extents_type::rank_type;
    using layout_type      = LayoutPolicy;
    using mapping_type     = typename layout_type::template mapping<Extents>;
    using allocator_type   = Allocator;
    
    // Constructors
    constexpr tensor();
    explicit constexpr tensor( const allocator_type& alloc );
    explicit constexpr tensor( const extents_type& s, const allocator_type& alloc = allocator_type() );
    explicit constexpr tensor( const mapping_type& m, const allocator_type& alloc = allocator_type() );

    constexpr tensor( const initializer_list< value_type >& il, const extents_type& s, const allocator_type& alloc = allocator_type() );
    constexpr tensor( const initializer_list< value_type >& il, const mapping_type& m, const allocator_type& alloc = allocator_type() );
    
    template < class InputIt >
    constexpr tensor( InputIt first, InputIt last, const extents_type& s, const allocator_type& alloc = allocator_type() );
    template < class InputIt >
    constexpr tensor( InputIt first, InputIt last, const mapping_type& m, const allocator_type& alloc = allocator_type() );
    
    template < class R >
    constexpr tensor( [[maybe_unused]] from_range_t, R&& rg, const extents_type& s, const allocator_type& alloc = allocator_type() );
    template < class R >
    constexpr tensor( [[maybe_unused]] from_range_t, R&& rg, const mapping_type& m, const allocator_type& alloc = allocator_type() );

    // NOTE: These constructors require one of:
    //    A: ( extents_type::rank_dynamic() == 0 ) && ( mapping_type().required_span_size() == size of initializer_list, iterator pair, or range )
    //    B: ( extents_type::rank_dynamic() == 1 ) && ( mapping_type( extents_type(N) ).required_span_size() == size of initializer_list, iterator pair, or range ) (for some integer value N)
    explicit constexpr tensor( const initializer_list< value_type >& il, const allocator_type& alloc = allocator_type() );
    template < class InputIt >
    constexpr tensor( InputIt first, InputIt last, const allocator_type& alloc = allocator_type() );
    template < class R >
    constexpr tensor( [[maybe_unused]] from_range_t, R&& rg, const allocator_type& alloc = allocator_type() );
    
    template < tensor_expression Tensor >
    explicit constexpr tensor( const Tensor& t, const allocator_type& alloc = allocator_type() );

    constexpr tensor( const tensor& rhs );
    constexpr tensor( const tensor& rhs, const allocator_type& alloc );
    constexpr tensor( tensor&& rhs ) noexcept;
    constexpr tensor( tensor&& rhs, const allocator_type& alloc );

    // Destructor
    constexpr ~tensor();

    // Assignment
    constexpr tensor& operator = ( tensor&& rhs ) noexcept( allocator_traits< allocator_type >::propagate_on_container_move_assignment ||
                                                            allocator_traits< allocator_type >::is_always_equal );
    constexpr tensor& operator = ( const tensor& rhs );
    template < tensor_expression Tensor >
    constexpr tensor& operator = ( const Tensor& rhs );
    // NOTE: This assignment operator requires the same requirements as the constructors
    constexpr tensor& operator = ( const initializer_list< value_type > il );

    // Members
    constexpr swap( tensor& rhs ) noexcept( allocator_traits< allocator_type >::propagate_on_container_swap ||
                                            allocator_traits< allocator_type >::is_always_equal );
    [[nodiscard]] constexpr bool empty() const noexcept;
    [[nodiscard]] constexpr const extents_type& extents() const noexcept;
    [[nodiscard]] constexpr size_type extent( rank_type n ) const noexcept;
    [[nodiscard]] static constexpr size_type static_extent( rank_type n ) noexcept;
    [[nodiscard]] constexpr size_type size() const noexcept;
    [[nodiscard]] constexpr size_type max_size() const noexcept;
    [[nodiscard]] constexpr size_type capacity() const noexcept;
    constexpr void resize( const extents_type& new_size );
    constexpr void resize( const extents_type& new_size, const value_type& value );
    constexpr void reserve( const extents_type& new_cap );
    constexpr void shrink_to_fit();
    [[nodiscard]] constexpr bool is_unique() const noexcept;
    [[nodiscard]] constexpr bool is_exhaustive() const noexcept;
    [[nodiscard]] constexpr bool is_strided() const noexcept;
    [[nodiscard]] static constexpr bool is_always_unique() noexcept;
    [[nodiscard]] static constexpr bool is_always_exhaustive() noexcept;
    [[nodiscard]] static constexpr bool is_always_strided() noexcept;
    [[nodiscard]] static constexpr rank_type rank() noexcept;
    [[nodiscard]] static constexpr rank_type rank_dynamic() noexcept;
    [[nodiscard]] constexpr size_type stride( rank_type n ) const noexcept;
    [[nodiscard]] constexpr const mapping_type& mapping() const noexcept;
    [[nodiscard]] constexpr const data_handle_type& data_handle() const noexcept;
    [[nodiscard]] constexpr data_handle_type& data_handle() noexcept;
    [[nodiscard]] constexpr allocator_type get_allocator() const noexcept;
    [[nodiscard]] constexpr const accessor_type& accessor() const noexcept;

    template < class ... OtherIndexType >
    [[nodiscard]] constexpr const_reference operator[]( OtherIndexType ... indices ) const;
    template < class ... OtherIndexType >
    [[nodiscard]] constexpr reference operator[]( OtherIndexType ... indices );

    template < tensor_expression Tensor >
    constexpr tensor& operator+=( const Tensor& t );
    template < tensor_expression Tensor >
    constexpr tensor& operator-=( const Tensor& t );
    constexpr tensor& operator*=( const value_type& value );
    constexpr tensor& operator/=( const value_type& value );
    constexpr tensor& operator%=( const value_type& value );
    constexpr tensor& operator&=( const value_type& value );
    constexpr tensor& operator|=( const value_type& value );
    constexpr tensor& operator^=( const value_type& value );
    constexpr tensor& operator>>=( const value_type& value );
    constexpr tensor& operator<<=( const value_type& value );
};

// Non-member functions
// Addition
// Substraction
// Negation
// Scalar Multiplication
// Scalar Division
// Matrix Multiplication
// Vector-Matrix Multiplication
// Vector Inner Product
// Vector Outer Product
// Transpose
// Conjugate
// Modulo

</code>
</pre>

Mandates:
- T is a complete object type that is neither an abstract class type nor an array type.
- is_same_v< Allocator::value_type, T > is true.
- is_same_v< AccessorPolicy::element_type, T > is true.
- Extents is a specialization of extents.
- Allocator shall meet the allocator requirements.
- LayoutPolicy shall meet the layout mapping policy requirements.
- AccessorPolicy shall meet the accessor policy requirements.

<h3>Tensor Expressions</h3>
TODO: Tensor Expressions

Design Questions {#questions}
=============================

These are issues for which different approaches may be taken. Many have pros and cons. The authors seek guidance on the best direction to take.

<h3>Fixed Size Tensor</h3>
On its face, the tensor container does not address optimization for fixed size tensor objects. For these objects - particularly of small size - optimizations provide significant performance improvements.
There are several ways this could be addressed:
1.  Split the functionality into two separate classes fs_tensor and dr_tensor - adopting similar language from P1385.
    fs_tensor would remove the allocator dependency - instead operating on a an array of objects - and remove a couple functions which serve no purpose for statically defined extents ( capacity, resize, reserve, shrink_to_fit, ... ).
    dr_tensor would adopt the existing tensor interface wholesale.
    This option would be particularly beneficial if further vector-like functions are adopted: Allowing fs_tensor to be the multidimensional corolary to std::array and dr_tensor the multidimensional corolary to std::vector.
    The issue of optimizing memory access is also not new. This approach would follow existing paradigms addressing this issue.
2.  Another partial solution would be to encourage the use of fixed buffers. This could be problematic for a couple reasons; however, allows focus on a single container class:
    - The abstraction provided by the allocator becomes less useful as the buffer size becomes too small for use by other objects.
    - This also fails to achieve full memory optimization - still requiring a pointer to a local buffer.
    A similar and full solution would be to package the pointer and allocator required by the tensor together - allowing for specialization of these members - when desired for fixed size tensors.
    - This is also problematic as full optimization cannot be achieved without violating the allocator requirements which the authors do not promote.
3.  Not addressing fixed size tensors would allow more focus on the existing tensor class; however, there are drawbacks:
    - Many existing applications already make use of these optimization to improvement performance.
    - Many existing c++ libraries such as Boost and Eigen already provide such optimizations. Not providing it would discourage standard adoption.
    - Given a fairly ubiquitous need, it is expected to be addressed at some point. Failure to address the need now could complicate further proposals.

<h3>Capacity and Reserve</h3>
The expected behavior of reserve also needs further guidance. There are several options to take:
1.  The reserve( const size_type& cap ) member function is a directive that informs a tensor object of a planned change in size so that it can manage the storage allocation accordingly.
    - After the call, the capacity is greater than or equal to cap if reallocation happens, and equal to the previous capacity otherwise.
    - Failure to reserve capacity shall result in no other side effects. (The tensor remains in a valid and usable state.)
    - Pointers and references into the tensor may not be valid after calling reserve.
    - After successfully calling reserve, any resize( const extents_type& s ) for which the resultant mapping_type(s).required_span_size() <= cap shall incur no re-allocation.

    Advantages:
    - This conforms to the existing interface for reserving existing containers.
    - Introduces little memory overhead comparable to existing containers.
    
    Disadvantages:
    - Not all layout policies are exhaustive or unique. This means the required_span_size() may be considerably less than the product of the desired extents. This requires the client to perform additional and perhaps error-prone logic to determine the desired capacity - potentially resulting in inefficiencies.
    - Resizing the multi-dimensional container can be prohibitively expensive without allowing reallocation. Consider resizing a dense {M,N} tensor with MxN capacity into an {1,MxN} tensor. MxN-1 elements must now be moved. More complex layout schemes will result in more complex and expensive sort-like approaches to perform resize; however, without a more expressive interface there is no other way to provide guarantees when re-allocation will not occur.
    - While implementers could choose to implement capacity as an extents_type (discussed in the next alternative), there is insufficient directive in how resize will be performed to make meaningful use of it. (As just discussed, {M,N} and {MxN,1} are very different tensors.)
2.  The reserve( const extents_type& e ) member function is a directive that informs a tensor object of a planned change in size, so that it can manage the storage allocation accordingly.
    - After the call, the capacity is greater than or equal to the mapping_type(e).required_span_size() if reallocation happens, and equal to the previous capacity otherwise.
    - Failure to reserve capacity shall result in no other side effects. (The tensor remains in a valid and usable state.)
    - Pointers and references into the tensor may not be valid after calling reserve.
    - After successfully calling reserve, any resize( const extents_type& s ) for which the resultant s.extent(r) <= e.extent(r) for all r in the range[0,rank()) shall incur no re-allocation.
    - After successfully calling reserve, any resize( const extents_type& s ) for which the resultant s.extent(r) > e.extent(r) for all r in the range[0,rank()) or mapping_type(s).required_span_size() > currrent mapping_type's required_span_size() re-allocation shall be attempted.
    - After successfully calling reserve, if neither of the above two conditions are true, then re-allocation behavior is implementation defined.
    
    Advantages:
    - This allows for implementations to provide similar guarantees to std::vector in so far as the efficiency of resizing.
    It encourages implementations of ordered strided layouts which still allow efficient memory access, but introduce appropriate gaps such that appropriately bounded resize operations only result iin redefining the extents and construction of new elements. No element moves would be required.
    - The client no longer has to interpret what required span size is needed for the desired extents.
    - It provides additional benefits in resize behavior which the mdarray adaptor interface cannot provide.
    
    Disadvantages:
    - Adds the most additional memory footprint.
3.  This option is the same as 2.; however, it introduces a separate template parameter for the capacity:
    <pre class="highlight">
    <code class="language-c++">
    template < class T,
               class Extents,
               class LayoutPolicy   = layout_right,
               class CapExtents     = Extents,
               class Allocator      = allocator<T>,
               class AccessorPolicy = default_accessor<T> >
    class tensor;
    </code>
    </pre>
    - This requires the additional mandate that for all r in the range [0,rank()), ( CapExtents::static_extent(r) == Extents::static_extent(r) || ( CapExtents::static_extent(r) != std::dynamic_extent && Extents::static_extent(r) == dynamic_extent ).
    - This allows for some parallels to the Boost static_vector and subsequent P0843 fixed_capacity_vector / static_vector; however, unlike those proposes - it does not guarantee local memory access. (An allocator is still used even if none of the capacity extents are dynamic.)
    
    Advantages:
    - Same advantages as 2.
    - Reduces memory footprint overhead - potentially to zero.
    
    Disadvantages:
    - Introduces another template parameter; however, this can be marginalized through appropriate aliasing.

<h3>Dynamic Only Extents</h3>
Avoids allocation on construction

<h3>[[[nodiscard]]] clarification</h3>
P0009 and P0600

<h3>Safe Memory Access</h3>
at(...)

<h3>Resize mapping_type</h3>
How should resize work?

<h3>Noexcept Swap and Move Mapping and AccessorPolicy</h3>
If the allocator is swappable and moveable, then container swap and move is expected to be noexcept. This requires additional constraints on mapping and accessor.

<h3>[[ assume( restrict p ) ]]</h3>
Owning tensor concepts may use such in a way similar to C99 restrict to achieve valarray-like optimization

<h3>Vector and Matrix Aliases</h3>

<h3>Limitations without Iterators</h3>
Some constructors/functions don't work well

<h3>Element-wise Functions</h3>
element-wise multiply and divide

<h3>Comparison Operators</h3>
Defining a norm

<h3>mdslice or subtensor</h3>
How should non-owning views be created. Relevant: P2630

<h3>Additional Vector-like functions</h3>
push_front, emplace_front, push_back, emplace_back, insert, ...

<h3>Rank One Extents Implicit Conversions</h3>
alleviates verbosity of rank one tensors

Acknowledgements {#acknowledge}
===============================

Related Work {#related}
=======================